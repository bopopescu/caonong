Mar 08 2018 10:28:01 twitter_cookies.py[line:117] INFO Get Cookies Finish [None]
Mar 08 2018 10:28:01 log.py[line:144] INFO Scrapy 1.4.0 started (bot: highcloud)
Mar 08 2018 10:28:01 log.py[line:147] INFO Overridden settings: {'NEWSPIDER_MODULE': 'highcloud.spiders', 'SPIDER_MODULES': ['highcloud.spiders'], 'BOT_NAME': 'highcloud'}
Mar 08 2018 10:28:01 middleware.py[line:53] INFO Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
Mar 08 2018 10:28:01 spiders.py[line:68] INFO Reading start URLs from redis key 'TwitterMasterSpider:task_id:start_urls' (batch size: 16, encoding: utf-8
Mar 08 2018 10:28:01 middleware.py[line:53] INFO Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'highcloud.middlewares.UserAgentChromeMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
Mar 08 2018 10:28:01 middleware.py[line:53] INFO Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
Mar 08 2018 10:28:01 middleware.py[line:53] INFO Enabled item pipelines:
['highcloud.pipelines.HighcloudPipeline']
Mar 08 2018 10:28:01 engine.py[line:256] INFO Spider opened
Mar 08 2018 10:28:02 logstats.py[line:48] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mar 08 2018 10:28:02 telnet.py[line:60] DEBUG Telnet console listening on 127.0.0.1:6023
Mar 08 2018 10:28:10 engine.py[line:238] DEBUG Crawled (200) <GET https://twitter.com/KwokMiles/status/933739147784749056> (referer: None)
Mar 08 2018 10:28:10 spiders.py[line:95] DEBUG Read 16 requests from 'TwitterMasterSpider:task_id:start_urls'
Mar 08 2018 10:28:11 __init__.py[line:181] WARNING D:\work\spider\lib\site-packages\bs4\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 2407 of the file D:\Program Files (x86)\JetBrains\PyCharm 5.0.3\helpers\pydev\pydevd.py. To get rid of this warning, change code that looks like this:

 BeautifulSoup(YOUR_MARKUP})

to this:

 BeautifulSoup(YOUR_MARKUP, "lxml")

  markup_type=markup_type))

